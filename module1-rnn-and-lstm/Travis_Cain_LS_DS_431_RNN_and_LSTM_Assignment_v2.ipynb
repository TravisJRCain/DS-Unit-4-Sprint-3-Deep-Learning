{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-MNA-DS11",
      "language": "python",
      "name": "u4-s3-mna-ds11"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "Travis_Cain_LS_DS_431_RNN_and_LSTM_Assignment_v2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TravisJRCain/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/module1-rnn-and-lstm/Travis_Cain_LS_DS_431_RNN_and_LSTM_Assignment_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr3TUiJfPlOs",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:18:20.442Z",
          "iopub.execute_input": "2020-06-15T18:18:20.453Z",
          "iopub.status.idle": "2020-06-15T18:18:20.513Z",
          "shell.execute_reply": "2020-06-15T18:18:20.523Z"
        },
        "id": "TblMnCjZPlOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:25:49.778Z",
          "iopub.execute_input": "2020-06-15T18:25:49.781Z",
          "iopub.status.idle": "2020-06-15T18:25:51.467Z",
          "shell.execute_reply": "2020-06-15T18:25:51.469Z"
        },
        "id": "7d_YXbbRPlO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = r.apparent_encoding\n",
        "data = r.text\n",
        "data = data.split('\\r\\n')\n",
        "toc = [l.strip() for l in data[44:130:2]]\n",
        "# Skip the Table of Contents\n",
        "data = data[135:]\n",
        "\n",
        "# Fixing Titles\n",
        "toc[9] = 'THE LIFE OF KING HENRY V'\n",
        "toc[18] = 'MACBETH'\n",
        "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
        "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
        "\n",
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
        "\n",
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "\n",
        "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
        "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
        "df_toc.loc[42, 'end'] = len(data)\n",
        "df_toc['end'] = df_toc['end'].astype('int')\n",
        "\n",
        "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-06-15T18:26:12.630Z",
          "iopub.execute_input": "2020-06-15T18:26:12.637Z",
          "iopub.status.idle": "2020-06-15T18:26:12.643Z",
          "shell.execute_reply": "2020-06-15T18:26:12.647Z"
        },
        "id": "nwj_Lhv5PlO5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a3075d5e-3f47-413e-99b7-c22a5b22e7ed"
      },
      "source": [
        "#Shakespeare Data Parsed by Play\n",
        "df_toc.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ALL’S WELL THAT ENDS WELL</td>\n",
              "      <td>2777</td>\n",
              "      <td>7738</td>\n",
              "      <td>ALL’S WELL THAT ENDS WELL\\r\\n\\r\\n\\r\\n\\r\\nConte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "      <td>7739</td>\n",
              "      <td>11840</td>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA\\r\\n\\r\\nDRA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "      <td>11841</td>\n",
              "      <td>14631</td>\n",
              "      <td>AS YOU LIKE IT\\r\\n\\r\\nDRAMATIS PERSONAE.\\r\\n\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "      <td>14632</td>\n",
              "      <td>17832</td>\n",
              "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
              "      <td>17833</td>\n",
              "      <td>27806</td>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 title  ...                                               text\n",
              "0            ALL’S WELL THAT ENDS WELL  ...  ALL’S WELL THAT ENDS WELL\\r\\n\\r\\n\\r\\n\\r\\nConte...\n",
              "1  THE TRAGEDY OF ANTONY AND CLEOPATRA  ...  THE TRAGEDY OF ANTONY AND CLEOPATRA\\r\\n\\r\\nDRA...\n",
              "2                       AS YOU LIKE IT  ...  AS YOU LIKE IT\\r\\n\\r\\nDRAMATIS PERSONAE.\\r\\n\\r...\n",
              "3                 THE COMEDY OF ERRORS  ...  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...\n",
              "4            THE TRAGEDY OF CORIOLANUS  ...  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icH7tAyCP3V-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b05e7494-45bc-4537-febf-ef1c09aea52a"
      },
      "source": [
        "# Import the necessary libraries.\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "from __future__ import print_function\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from keras.utils.data_utils import get_file\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQPd0orpP6po",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71db5dc8-9f55-4d10-97a1-4b96f6ce6927"
      },
      "source": [
        "# Text we are using\n",
        "\n",
        "path = get_file('Shakespeare.txt', origin='https://www.gutenberg.org/files/100/100-0.txt')\n",
        "\n",
        "with io.open(path, encoding='utf-8') as w:\n",
        "  text = w.read().lower()\n",
        "  print('Length:', len(text))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length: 5573152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01_W2rgvQdwF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffed0c0f-4878-43db-a09b-1adb3619fa9e"
      },
      "source": [
        "# Character count\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print('Total Characters:', len(chars))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters: 79\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "angE4jYmQpSU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b02d723-0520-4d3f-cc62-cbe537de245e"
      },
      "source": [
        "chars"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\t',\n",
              " '\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '_',\n",
              " '`',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '|',\n",
              " '}',\n",
              " 'à',\n",
              " 'â',\n",
              " 'æ',\n",
              " 'ç',\n",
              " 'è',\n",
              " 'é',\n",
              " 'ê',\n",
              " 'î',\n",
              " 'œ',\n",
              " '—',\n",
              " '‘',\n",
              " '’',\n",
              " '“',\n",
              " '”',\n",
              " '\\ufeff']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evM1I_7vQvCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lookup Tables, make character adnd indices interchangable and transmutable\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MSdNE0tSjao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b28c826-d99b-4964-a10f-3f4196c8b34e"
      },
      "source": [
        "# Create the sequence data\n",
        "\n",
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "\n",
        "  sequences.append(encoded[i : i + maxlen])\n",
        "  next_chars.append(encoded[i + maxlen])\n",
        "\n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  1114623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgpXJyZeSjda",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "caacf330-fed4-42b7-fcab-fc8a8d4ef033"
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[78,\n",
              " 1,\n",
              " 51,\n",
              " 53,\n",
              " 50,\n",
              " 45,\n",
              " 40,\n",
              " 38,\n",
              " 55,\n",
              " 2,\n",
              " 42,\n",
              " 56,\n",
              " 55,\n",
              " 40,\n",
              " 49,\n",
              " 37,\n",
              " 40,\n",
              " 53,\n",
              " 42,\n",
              " 75,\n",
              " 54,\n",
              " 2,\n",
              " 55,\n",
              " 43,\n",
              " 40,\n",
              " 2,\n",
              " 38,\n",
              " 50,\n",
              " 48,\n",
              " 51,\n",
              " 47,\n",
              " 40,\n",
              " 55,\n",
              " 40,\n",
              " 2,\n",
              " 58,\n",
              " 50,\n",
              " 53,\n",
              " 46,\n",
              " 54]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DripogpPSjkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating x and y\n",
        "\n",
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "  for t, char in enumerate(sequence):\n",
        "    x[i,t,char] = 1\n",
        "\n",
        "  y[i, next_chars[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Re9hHexSjpN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c2531d1-dca3-4b08-d6b1-52ab81603919"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1114623, 40, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy9r1J1jSjn1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "625c110d-10cd-419b-fa80-f90ed8eb51ae"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1114623, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT2j8YhhSji2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build LSTM model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZnRoSUVSjhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq4pbZv0WE45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXylIsYdWE9p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "280309a5-b095-4e08-948c-7bc778bc0ee3"
      },
      "source": [
        "# fit the model\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "34832/34832 [==============================] - ETA: 0s - loss: 1.9447\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"e once more; once more search with me.\n",
            " \"\n",
            "e once more; once more search with me.\n",
            "    buty as amy queet theuclow yout of must lay\n",
            "holdseld, petter the live,\n",
            "    with can it diggn gurd me stands’d whites like,\n",
            "    poor mo, reredy with the palaint, and told\n",
            "the douchor, and wither awerme. for bogrny.\n",
            "\n",
            "\n",
            "ie. well-princh,\n",
            "  told. gleak preadamce to, he bether is tosck?\n",
            "    prind be to most more are in druy?\n",
            "\n",
            " [withimpaid. whon, thattw, and oo corelf.\n",
            "                                 \n",
            "34832/34832 [==============================] - 472s 14ms/step - loss: 1.9447\n",
            "Epoch 2/10\n",
            "34829/34832 [============================>.] - ETA: 0s - loss: 1.6592\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"ncle to the king\n",
            "  henry, surnamed bolin\"\n",
            "ncle to the king\n",
            "  henry, surnamed boling prince, and this, it by prinded\n",
            "when you shall ghood aboodful no mighthrow, a falure compbaind see; it is their mady; reseff courtewrein.\n",
            "  dinedn. a prothey show is there\n",
            "    to have she shoraves did as thou lare toucher fram.\n",
            "      laving some young yau.\n",
            "beesing he will takes do reather you pross\n",
            "    whese all speight tobtry. be same a do.\n",
            "  gold debrabiol, knig and thee; o’ a nowl’d time\n",
            "\n",
            "   \n",
            "34832/34832 [==============================] - 470s 13ms/step - loss: 1.6592\n",
            "Epoch 3/10\n",
            "34829/34832 [============================>.] - ETA: 0s - loss: 1.5694\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \" woman; but i must comfort the weaker ve\"\n",
            " woman; but i must comfort the weaker veria,\n",
            "and we minds and beshecling she will emputed\n",
            "inon, powe’s worldm'd. ere bid my dognous,\n",
            "    ire, till night, and the finth cours some:\n",
            "and timess from him, the fathy sold lady.\n",
            "\n",
            "hamlet.\n",
            "what it are’s to the muning, of manited,\n",
            "    that siek i pleasucely earled alses my manners.\n",
            "\n",
            "olonaus,\n",
            "chafflew om him,\n",
            "o is men ford he draw acd to be as price.\n",
            "    o’ll first for looks to. conside, than hand\n",
            "34832/34832 [==============================] - 472s 14ms/step - loss: 1.5694\n",
            "Epoch 4/10\n",
            "34830/34832 [============================>.] - ETA: 0s - loss: 1.5198\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"see it but a holiday.\n",
            "  constance.  [ris\"\n",
            "see it but a holiday.\n",
            "  constance.  [rise._]\n",
            "\n",
            "\n",
            "      beloven of dread of all my light. that fire oncent, rovenge\n",
            "    year deflicessands, which wime. we and an enlone to they fromings driehly\n",
            "us the dons rook in thy soul.\n",
            "  anterious.\n",
            "hark 'palil: i thanking, hending and spread,\n",
            "foot offito in ane hither; or need, like too,\n",
            "uncals, leave heav'nty?\n",
            "\n",
            "carello.\n",
            "no thle, stay you to to me go, loyg, be making\n",
            "    while, but porterry.\n",
            "  truth. \n",
            "34832/34832 [==============================] - 467s 13ms/step - loss: 1.5198\n",
            "Epoch 5/10\n",
            "34830/34832 [============================>.] - ETA: 0s - loss: 1.4876\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"d. away with her,\n",
            "and pen her up.\n",
            "\n",
            "queen\"\n",
            "d. away with her,\n",
            "and pen her up.\n",
            "\n",
            "queen.\n",
            "who blishos’s humoraing as;\n",
            "    i he’ in your lawly it ever which,\n",
            "a flike a chion’d should hear the chipin\n",
            "    the mights, an ard dan help abulishardedwoodis.\n",
            "\n",
            "hommotena.\n",
            "that sig clavince in a wand 'pmst your lips us; and gaze\n",
            "a know thy forg] and with the schorst glouces i’ll saint\n",
            "fad but believe thee, look might mightrows,—\n",
            "what’s theeed such a most guvent and thou authilloks\n",
            "    you.  down\n",
            "34832/34832 [==============================] - 471s 14ms/step - loss: 1.4876\n",
            "Epoch 6/10\n",
            "34829/34832 [============================>.] - ETA: 0s - loss: 1.4646\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"services awhile; but my full heart\n",
            "    r\"\n",
            "services awhile; but my full heart\n",
            "    rome a throat have call'd walls with love;\n",
            "though thy ground of nature of pefflues!\n",
            "  quirlet. said'ry stand.                          exit court, thy cateat with abast,\n",
            "    and sum one says, we name off\n",
            "    exemperly. i take whose wisence and fire and lipe thee shall\n",
            "    which shall make off her cleat of were make.\n",
            "\n",
            "hamlet.\n",
            "what resain’d, as bids.\n",
            "here is awher kind firety lead; truch out of the c\n",
            "34832/34832 [==============================] - 469s 13ms/step - loss: 1.4645\n",
            "Epoch 7/10\n",
            "34829/34832 [============================>.] - ETA: 0s - loss: 1.4465\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"erance doth o’erskip\n",
            "when grief hath mat\"\n",
            "erance doth o’erskip\n",
            "when grief hath matchanies, they, sure came\n",
            "laid nor spoken of a very hilling, and unon perey corces. here's to thou unto dellouse unto delikence,:\n",
            "    and thou not from renacate lovely hangtase pace, and\n",
            "    as that’s flan’s man angon in heal-\n",
            "laudia.\n",
            "\n",
            "first lion what, i deal, aboves our sorrodal,\n",
            "fforew nor dressow knock on my joy.\n",
            "\n",
            "amberowar’d, charles shall’nedy with teeph them\n",
            "    affecius some dread come;\n",
            "    \n",
            "34832/34832 [==============================] - 469s 13ms/step - loss: 1.4465\n",
            "Epoch 8/10\n",
            "34832/34832 [==============================] - ETA: 0s - loss: 1.4319\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"n thee?\n",
            "    go, base intruder, over-ween\"\n",
            "n thee?\n",
            "    go, base intruder, over-ween save be a room\n",
            "    to my almilish and uncle spoil agay and\n",
            "thairs’ the quick pass. he his wrimon or heles-\n",
            "which roable, virtue are acpeth the woman.\n",
            "\n",
            "imoger.\n",
            "if you make hymath.\n",
            "\n",
            "beard.\n",
            "titaning, my swift me to live flatus.\n",
            "\n",
            "\n",
            "      prospero.\n",
            "      or shames will not by marb on on live,\n",
            "brink the wourt, he been a captime.\n",
            "\n",
            "mealan.\n",
            "thy boyage-for proud, i willly, sillonic life\n",
            "cares marry, most gr\n",
            "34832/34832 [==============================] - 470s 13ms/step - loss: 1.4319\n",
            "Epoch 9/10\n",
            "34831/34832 [============================>.] - ETA: 0s - loss: 1.4203\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"t is as an ancient tale new told\n",
            "    and\"\n",
            "t is as an ancient tale new told\n",
            "    and see die led upon the samers be were,\n",
            "that or age in bitter forar?\n",
            "\n",
            "bandard.\n",
            "pratest the shed tell, there is truts of saturning.\n",
            "\n",
            "daughter. or austreat and behold.\n",
            "\n",
            "contentius.\n",
            "bull have yaurs-masterous villanting truly not the post\n",
            "    as our burgeft simple capting with the\n",
            "more will shoke what his aciess firehing;\n",
            "har your noble fall bolb my gutct tebtaines not;\n",
            "and i had have would in one made \n",
            "34832/34832 [==============================] - 470s 14ms/step - loss: 1.4203\n",
            "Epoch 10/10\n",
            "34829/34832 [============================>.] - ETA: 0s - loss: 1.4100\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \".\n",
            "\n",
            " alarum. enter brutus and messala.\n",
            "\n",
            "b\"\n",
            ".\n",
            "\n",
            " alarum. enter brutus and messala.\n",
            "\n",
            "bertram.\n",
            "she is not your river.\n",
            "\n",
            " [_exeunt.]\n",
            "\n",
            "eavis.\n",
            "your tarriad will near his fext of thy sword\n",
            "    trutule love was sagure gentleman.\n",
            "  cause, marbiana.\n",
            "  monton. your gate-like a king, and not secret be town cause;\n",
            "my beauty in thy entrry lighty toose in sort burnt in mysethess of my liege,\n",
            "my love joy me.\n",
            "\n",
            "\n",
            "      enter hearence. seenzus, like a boy, that we' womy in the dogue.\n",
            "  second soldier\n",
            "34832/34832 [==============================] - 473s 14ms/step - loss: 1.4100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7e3a5bb208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}